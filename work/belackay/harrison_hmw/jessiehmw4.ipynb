{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6887373",
   "metadata": {},
   "source": [
    "# ASTR 8060 (Observational Methods) Sp26 Homework 4 \n",
    "## Harrison Blake-Goszyk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdfd4e0",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c09841",
   "metadata": {},
   "source": [
    "## 1): Start a Jupyter notebook that will contain all sort of things you will learn in the course of your data analysis. Keep here your procedures that you run so that you can quickly re-run them with a few keystrokes. Also keep here anything you’d keep in a paper logbook regarding notes about your reduction. Markdown in your Jupyter notebook will take the place of formal reduction notes. The quality of the this file will make up one component of the grade for this homework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e59b62",
   "metadata": {},
   "source": [
    "## 2): Examine the images in DS9 to become familiar with where the overscan region of the chip is (on both sides of the data section; make note of where this is). Look at examples of bias images, dark images, and flats so that you can know by inspection what kind of image you are viewing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75489bd1",
   "metadata": {},
   "source": [
    "## 3): Assess the RMS and mean levels of an image. Use Python to practice plotting lines and columns of data from one of the bias images. Use Python to compute the mean and RMS of a region near the center of the chip."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c01aff",
   "metadata": {},
   "source": [
    "## 4): Open Phillip Massey’s users’s guide to ccd reductions with IRAF, linked on the class website. Use this as a rough guide, but we won’t follow everything he recommends (there are just too many ways to do the same thing!). An example of these steps in action can be found at the CCD reduction and photometry guide Github tutorial also linked from the class website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd548c75",
   "metadata": {},
   "source": [
    "## 5): Examine the all bias exposures (or overscan regions throughout the night) and quantify how much the bias level changes throughout the night. Compare the mean level of the biases to the mean levels of the overscan regions from other files throughout the night. How much variation do you find? Make an argument for whether it would be a good or bad idea to combine all of the biases to make a master bias and subtract that from all the images versus using the overscan region of each image as an estimate of the bias level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291ba880",
   "metadata": {},
   "source": [
    "## 6): Using CCDPROC.SUBTRACT_OVERSCAN and CCDPROC.TRIM_IMAGE, fit and subtract the overscan region of each image and trim the image to remove the overscan region. In the overscan fitting, try out ’chebyshev’, ’legendre’, and ’hermite’, and ’polynomial’ of various orders for the fitting function. Qualitatively try to summarize the differences between the functions (you can also look up and summarize the properties of these types of polynomials, but this is not required). Also try orders 1 through about 8, and make an argument for how large an order is necessary to fit the overscan region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3656bd26",
   "metadata": {},
   "source": [
    "## 7): Combine the bias frames into a master bias frame using CCDPROC.COMBINE. By visual inspection or using image statistics, decide whether it is appropriate to combine all your bias exposures to make 1 master bias, or whether you need to restrict the input frames because of variations among your bias frames. Are there trends in your sequence of bias frames? Does either the level, or the pattern of the bias change throughout the night? If so, by how much? How much noise would you be adding to your data if you decide to do a bias subtraction in addition to your overscan subtraction. Do the subtraction of your master bias from all other science frames if you can justify that it is warranted.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d602ba59",
   "metadata": {},
   "source": [
    "## 8). Now examine the ‘dark’ images quantitatively and estimate the range of dark current (electrons per pixel per second) you see in the darks. WIRO Prime’s gain is 2.5 e−/ADU. Use Python to inspect the header and see the exposure time in each of the darks. Pixel values will vary! Be careful to avoid being fooled by cosmic rays, which will appear as large bright spots usually spread over a few pixels, whereas high dark current is usually isolated to just individual pixels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc6384d",
   "metadata": {},
   "source": [
    "## 9). Use CCDPROC.COMBINE to combine darks together to make a master dark. You will need to play with different combination parameters to see which one does the best job of eliminating cosmic rays. At a minimum, do:\n",
    "## • A straight average of all dark frames.\n",
    "## • A straight median of all dark frames.\n",
    "## • An average where outlier pixels are rejected if they are more than 3σ away from the mean.\n",
    "## • A median where outlier pixels are rejected if they are more than 3σ away from the mean.\n",
    "## Use the resulting RMS in the master image as an indicator of which combination procedure is best. Compare your master dark to your master bias to estimate the significance of the highest dark count pixels. How many times larger is the typical dark current than the noise (σ) in the master image?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
